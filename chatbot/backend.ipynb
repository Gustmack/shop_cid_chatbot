{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import os\n",
    "import json\n",
    "import openai\n",
    "import pickle\n",
    "import getpass\n",
    "from openai import OpenAI\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.docstore.document import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carrega a chave da API a partir do arquivo JSON\n",
    "with open('config.json', 'r') as file:\n",
    "    config = json.load(file)\n",
    "    os.environ['OPENAI_API_KEY'] = config.get('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define o caminho relativo para a pasta 'splits' dentro do projeto\n",
    "current_directory = os.getcwd()\n",
    "splits_directory = os.path.join(current_directory, 'splits')\n",
    "splits_filepath = os.path.join(splits_directory, 'splits.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para carregar os splits\n",
    "def load_splits(filepath):\n",
    "    with open(filepath, 'rb') as file:\n",
    "        splits = pickle.load(file)\n",
    "    return splits\n",
    "\n",
    "# Carregar os splits usando o caminho relativo\n",
    "splits = load_splits(splits_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\gust_\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:141: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 0.3.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAIEmbeddings`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "# Definindo os embeddings antes de carregar o FAISS\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-ada-002\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregando o índice FAISS localmente\n",
    "faiss_db = FAISS.load_local(\"faiss_index\", embeddings, allow_dangerous_deserialization=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar o retriever a partir do faiss_db\n",
    "retriever = faiss_db.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI()\n",
    "\n",
    "def generate_response(query):\n",
    "    # Recuperar as 5 combinações mais relevantes\n",
    "    relevant_docs = retriever.invoke(query)\n",
    "    context = \" \".join([doc.page_content for doc in relevant_docs])\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    Você é um assistente de perguntas e respostas. Seu objetivo é responder perguntas com a maior precisão possível com base nos documentos fornecidos. Responda sempre em português.\n",
    "\n",
    "    Contexto: {context}\n",
    "\n",
    "    Pergunta: {query}\n",
    "    Resposta:\n",
    "    \"\"\"\n",
    "    \n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"Você é um assistente de perguntas e respostas. Seu objetivo é responder perguntas com a maior precisão possível com base nas instruções e no contexto fornecido. Responda sempre em português.\"},\n",
    "            {\"role\": \"user\", \"content\": f\"Contexto: {context} Pergunta: {query}\"}\n",
    "        ],\n",
    "        max_tokens=150,\n",
    "        temperature=0.5\n",
    "    )\n",
    "\n",
    "    #print(completion.choices[0].message)\n",
    "    return completion.choices[0].message.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Os representantes dos Recursos Humanos do Shopping Cidadão são Carlos Fernandez Rodriguez, Priscila Fonseca e Luciano Catarino. Suas informações de contato são:\n",
      "\n",
      "- Carlos Fernandez Rodriguez | Recursos Humanos: carlos.fernandez@shopcidadao.com.br\n",
      "- Priscila Fonseca | Recursos Humanos: priscila.fonseca@shopcidadao.com.br\n",
      "- Luciano Catarino | Recursos Humanos: luciano.catarino@shopcidadao-mg.com.br\n"
     ]
    }
   ],
   "source": [
    "# Exemplo de uso\n",
    "query = \"Quem é o representante dos Recursos HUmanos do Shopping Cidadão?\"\n",
    "resposta = generate_response(query)\n",
    "print(resposta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
